{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/assignment1/task1a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/task2b_binary_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/task2b_binary_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "Early stopping afther 34 epochs and 1039 global steps\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/assignment1/task2d.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2e)\n",
    "The data's original structure, often featuring long sequences of identical numbers, can hinder model generalization and cause learning spikes with new sequences. Shuffling the data prior to training is recommended to ensure a more balanced distribution and improve generalization.\n",
    "\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/task2e_train_accuracy_shuffle_difference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b)\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/task3b_softmax_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/task3b_softmax_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "At 3000 steps, a divergence occurs between training and validation accuracy: training accuracy keeps improving, while validation accuracy appears to converge. This likely indicates overfitting, as the model starts learning dataset noise rather than underlying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/assignment1/task4a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "Training two models with different L2 regularization values (`λ = 0.0` and `λ = 1.0`) and visualizing their weights reveals that the model with `λ = 1.0` has less noisy weights. This is because L2 regularization penalizes large weights, encouraging the model to maintain smaller, simpler weights, which reduces overfitting and results in a smoother, more generalized representation of the data.\n",
    "\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/assignment1/lambda_0.png)\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/assignment1/lambda_1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/task4c_softmax_train_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "Regularization imposes constraints on the model to prevent overfitting, but excessive constraints can lead to underfitting, resulting in poorer performance on both the training and validation datasets. Additionally, the regularization parameter (lambda) needs proper tuning to strike the right balance between model complexity and generalization performance. Failure to tune this parameter effectively can lead to suboptimal validation accuracy. Therefore, careful management of regularization strength and hyperparameter tuning is crucial for achieving optimal model performance.\n",
    "\n",
    "![](task4d_l2_reg_norms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "The plot illustrates an inverse relationship between the regularization parameter λ and the L2 norm of the weights. As λ increases, the L2 norm decreases, indicating that higher regularization leads to smaller weight vectors. This is a characteristic effect of L2 regularization, which aims to prevent overfitting by penalizing large weights. The most substantial decrease in the L2 norm is observed with increasing λ, especially transitioning from λ = 0.001 to λ = 1.0.\n",
    "\n",
    "![](/Users/eirikvarnes/TDT4265_ComputerVision/task4c_l2_norm_vs_lambda.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdt4265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
